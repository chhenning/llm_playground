{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc5b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from src.data_models import TextChunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b9d296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA_SERVER_URL = \"http://localhost:32000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92980b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"## Text Chunk Extraction\n",
    "\n",
    "### Task description\n",
    "\n",
    "You are an expert at dividing long-form documents into **coherent, topic-focused text chunks**.\n",
    "\n",
    "Each chunk must focus on **one clear topic or idea** and be **semantically complete** on its own.  \n",
    "Chunks should not cut off sentences, definitions, arguments, or important context.\n",
    "\n",
    "The goal is to produce **clean, self-contained text segments** that can later be used to generate precise questions or embeddings.\n",
    "\n",
    "Chunks **do not need to be small or uniform in size**.  \n",
    "Instead, group sentences and paragraphs that naturally belong together, such as:\n",
    "- A single argument or analysis thread\n",
    "- One news item or case study\n",
    "- A complete explanation of a concept\n",
    "- A short Q&A or FAQ exchange\n",
    "- A subsection of a longer essay or newsletter\n",
    "\n",
    "### Important rules (strict)\n",
    "\n",
    "- **Do not paraphrase, summarize, rewrite, or edit** the text.\n",
    "- **Do not drop or skip any text**. Every character must appear in exactly one chunk.\n",
    "- **Preserve original wording and formatting**, including:\n",
    "  - Paragraph breaks\n",
    "  - Lists and bullet points\n",
    "  - Quotes\n",
    "  - Emphasis (bold, italics, headings, etc.)\n",
    "- Keep **tables, figures, footnotes, or parenthetical explanations** with the text that references them.\n",
    "- Do **not merge unrelated topics** into a single chunk.\n",
    "- Do **not split a single topic** across multiple chunks unless the topic clearly shifts.\n",
    "- Output **only valid JSON**, matching the provided schema.\n",
    "- Do **not include explanations, commentary, or metadata outside the JSON**.\n",
    "\n",
    "### Chunking guidance (heuristics)\n",
    "\n",
    "Use topic boundaries such as:\n",
    "- A clear shift in subject matter\n",
    "- A new example or case study\n",
    "- A transition like “But,” “However,” “Meanwhile,” or “Separately” when it introduces a new idea\n",
    "- Section headers or implicit newsletter breaks\n",
    "\n",
    "Avoid splitting:\n",
    "- Mid-argument\n",
    "- Mid-example\n",
    "- Between a claim and its explanation\n",
    "- Between a question and its answer\n",
    "\n",
    "### Output format\n",
    "\n",
    "Use the supplied JSON schema to return a well-formed JSON object.\n",
    "\n",
    "The schema corresponds to the following Pydantic model:\n",
    "\n",
    "class TextChunks(BaseModel):\n",
    "    chunks: List[str]\n",
    "\n",
    "Your output must be a JSON object with a single key \"chunks\", whose value is an array of strings.\n",
    "Each string is one extracted chunk of text.\n",
    "\n",
    "### Inference\n",
    "\n",
    "Here is the text to process:\n",
    "\n",
    "---\n",
    "\n",
    "## Examples\n",
    "\n",
    "### Example 1: Simple analytical paragraph\n",
    "\n",
    "Input text:\n",
    "Apple reported earnings yesterday. Revenue was flat year over year, but margins improved due to lower component costs.\n",
    "This matters because Apple has been under pressure from investors to show pricing power.\n",
    "\n",
    "Separately, the Fed released minutes from its last meeting.\n",
    "\n",
    "Expected output:\n",
    "{\n",
    "  \"chunks\": [\n",
    "    \"Apple reported earnings yesterday. Revenue was flat year over year, but margins improved due to lower component costs.\\nThis matters because Apple has been under pressure from investors to show pricing power.\",\n",
    "    \"Separately, the Fed released minutes from its last meeting.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "### Example 2: Newsletter-style argument with continuation\n",
    "\n",
    "Input text:\n",
    "The interesting thing about convertible bonds is that they sit between debt and equity.\n",
    "They pay interest like bonds, but can convert into shares.\n",
    "\n",
    "That optionality is valuable when volatility is high.\n",
    "It also creates weird incentives for issuers.\n",
    "\n",
    "Expected output:\n",
    "{\n",
    "  \"chunks\": [\n",
    "    \"The interesting thing about convertible bonds is that they sit between debt and equity.\\nThey pay interest like bonds, but can convert into shares.\\n\\nThat optionality is valuable when volatility is high.\\nIt also creates weird incentives for issuers.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "### Example 3: Bulleted list that must stay together\n",
    "\n",
    "Input text:\n",
    "There are three ways this trade can go wrong:\n",
    "- Rates fall faster than expected\n",
    "- Liquidity dries up\n",
    "- The counterparty fails\n",
    "\n",
    "Each of these risks is manageable, but not trivial.\n",
    "\n",
    "Expected output:\n",
    "{\n",
    "  \"chunks\": [\n",
    "    \"There are three ways this trade can go wrong:\\n- Rates fall faster than expected\\n- Liquidity dries up\\n- The counterparty fails\\n\\nEach of these risks is manageable, but not trivial.\"\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa8bfe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# AI rollup\\n\\nPeople have been worried for a while\\xa0about private equity\\xa0buying up every company and coming to dominate the economy. “Private equity,” in this worry, tends to mean specifically the large private-equity firms that have their roots in doing leveraged buyouts of mature cash-flowing companies. But the fun hipster alternative is, what if\\xa0*venture capital*buys up every company and comes to dominate the economy? Historically no\\xa0one\\xa0worried about that much, because historically venture capital was about making concentrated bets on small startups that might change the world, not about buying the local pest-control company or medical practice in every town in America. But that’s changing.\\xa0We have talked a few times about “AI rollups,” where a venture capital firm buys a bunch of small companies, combines them, and sprinkles them with artificial intelligence.\\n\\nOne way to think about it is that each of PE and VC has a powerful general-purpose technology that it can apply indiscriminately to every company. PE’s magic technology is leverage: You buy the local plumber or pest control company or medical practice, you put a lot of non-recourse debt on it, you get a lot of upside if it does well and limited downside if it does poorly. VC’s magic technology is artificial intelligence: You buy the local plumber or pest control company or medical practice, you replace the customer-service reps and bookkeepers with AI agents, you cut costs and improve profits, and\\xa0*eventually* you also replace\\xa0the plumbers and exterminators and doctors with AI and then you really start to make money. Here’s a Financial Times story about AI rollups:\\n\\n> Top venture capital firms are borrowing a strategy from the private equity playbook, pumping money into tech start-ups so they can “roll up” rivals to build a sector-dominating conglomerate. ...\\n>\\n> The approach mirrors the strategies long deployed by private equity investors, which have built behemoths in fragmented industries such as healthcare, waste management or building services by agglomerating smaller businesses and centralising operating costs.\\n>\\n> It marks a new direction for VCs, which traditionally target fast-growing technology start-ups in nascent industries. The roll-up strategy creates an avenue for VCs to generate liquidity from their portfolios at a time when initial public offerings and dealmaking have slowed.\\n>\\n> Where private equity firms typically make heavy use of debt and slash costs in a roll-up, VCs claim improvements to efficiency and margins will come from infusing technology into the companies.\\n>\\n> [Thrive Capital-backed wealth startup] Savvy, for instance, is using AI to take on back office tasks such as pulling data for the half a dozen forms that might be needed for any one transaction.\\n\\nMostly I want to see a future where small cash-flowing companies are regularly the subjects of\\xa0*bidding wars*between private equity and venture capital. Who will win? At what point will private equity’s operational and financial expertise lose out to venture capital’s ability to deploy AI? At what point will private equity be just as good at deploying AI? Who has better access to capital? Historically private equity funds were bigger, but there is no cheaper source of capital in 2025 than saying “we’re doing AI.”\\n\\nOn the other hand, what makes the VC firms so good at deploying AI? VC firms have a pleasing combination of (1) being in the business of raising capital and investing in companies and (2) being tech-focused and enthusiastic about AI. But it is not obvious to me that VC firms are staffed with lots of domain experts in AI. Arguably the people who should be doing the AI rollups are\\xa0*AI companies*. In that vein, here is a blog post from AI lab Anthropic about how it got into the vending-machine business:\\n\\n> Anthropic partnered with Andon Labs, an AI safety evaluation company, to have Claude Sonnet 3.7 operate a small, automated store in the Anthropic office in San Francisco. …\\n>\\n> Far from being just a vending machine, Claude had to complete many of the far more complex tasks associated with running a profitable shop: maintaining the inventory, setting prices, avoiding bankruptcy, and so on. …\\n>\\n> The shopkeeping AI agent — nicknamed “Claudius” for no particular reason other than to distinguish it from more normal uses of Claude — … decided what to stock, how to price its inventory, when to restock (or stop selling) items, and how to reply to customers. ... In particular, Claudius was told that it did not have to focus only on traditional in-office snacks and beverages and could feel free to expand to more unusual items.\\n\\nClaudius\\xa0had an important disadvantage in that it has no hands and so could not stock the vending machines itself, but it did have “an email tool for requesting physical labor help (Andon Labs employees would periodically come to the Anthropic office to restock the shop) and contacting wholesalers.” And it turns out that\\xa0it is not yet as good at running a vending machine operation as a human would be:\\n\\n> If Anthropic were deciding today to expand into the in-office vending market,\\xa0we would not hire Claudius. As we’ll explain, it made too many mistakes to run the shop successfully. However, at least for most of the ways it failed, we think there are clear paths to improvement—some related to how we set up the model for this task and some from rapid improvement of general model intelligence.\\n\\nI am always wrong in my intuitions about what tasks will be easy\\xa0or hard\\xa0for AI. If you had asked me a week ago, “which task will be easier for a computer, driving a car or operating a vending machine,” I would have said “driving a car requires integrating lots of visual and other data in real time and seems really complicated, while a vending machines just …\\xa0are …\\xa0computers? And have been operated by computers for decades?” But, nope, vending machine operation is still hard for AI. To be fair, running a vending machine\\xa0*at the Anthropic office*poses unusual challenges:\\n\\n> An employee light-heartedly requested a tungsten cube, kicking off a trend of orders for “specialty metal items” (as Claudius later described them). Another employee suggested Claudius start relying on pre-orders of specialized items instead of simply responding to requests for what to stock, leading Claudius to send a message to Anthropic employees in its Slack channel announcing the “Custom Concierge” service doing just that. ...\\n>\\n> Claudius was cajoled via Slack messages into providing numerous discount codes and let many other people reduce their quoted prices\\xa0*ex post*\\xa0based on those discounts. It even gave away some items, ranging from a bag of chips to a tungsten cube, for free.\\n\\nI feel like this demonstrates something deep about artificial intelligence.\\xa0A normal dumb vending machine, bound by inflexible programming, simply would not give away a tungsten cube for free. But you’ve probably met a human being who *would*give away a tungsten cube for free, if you asked nicely. [[1]](#footnote-1)  If you are trying to build artificial general intelligence, if you want your computer to address real-world situations the way an intelligent human would, you run the risk that it will be flattered or bamboozled into giving away free tungsten cubes.\\n\\n|  |  |\\n| --- | --- |\\n|  | |\\n| |  | | --- | |  | | |'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text = open(\"data/text/money_stuff.md\").read()\n",
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf84558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt tokens  : 868\n",
      "Extracted text tokens : 1548\n",
      "Total tokens          : 2416\n"
     ]
    }
   ],
   "source": [
    "def count_tokens(prompt: str) -> int:\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            url=f\"{LLAMA_SERVER_URL}/tokenize\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            data=json.dumps(\n",
    "                {\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "\n",
    "        response_json = response.json()\n",
    "        tokens = response_json.get(\"tokens\", [])\n",
    "\n",
    "        return len(tokens)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return -1\n",
    "\n",
    "system_prompt_tokens = count_tokens(system_prompt)\n",
    "extracted_text_tokens = count_tokens(extracted_text)\n",
    "total_tokens = system_prompt_tokens + extracted_text_tokens\n",
    "\n",
    "print(f\"System prompt tokens  : {system_prompt_tokens}\")\n",
    "print(f\"Extracted text tokens : {extracted_text_tokens}\")\n",
    "print(f\"Total tokens          : {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1739cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(system_prompt, user_prompt, text):\n",
    "    try:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt + \"\\n\\n\" + text,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        payload = {\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": {\n",
    "                \"type\": \"json_object\",\n",
    "                \"schema\": TextChunks.model_json_schema(),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            url=f\"{LLAMA_SERVER_URL}/v1/chat/completions\",\n",
    "            data=json.dumps(payload),\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "\n",
    "        content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return TextChunks.model_validate_json(content)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16482684",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Below is the extracted text from a document.\n",
    "\n",
    "Your task is to read the text carefully and split it into **coherent, topic-focused chunks**.\n",
    "\n",
    "Rules:\n",
    "- Each chunk must focus on **one clear topic or idea**.\n",
    "- Do **not** summarize, paraphrase, rewrite, or modify the text in any way.\n",
    "- Do **not** skip or omit any content. Every character must appear in exactly one chunk.\n",
    "- Preserve the **exact text and formatting** as it appears, including:\n",
    "  - Paragraph breaks\n",
    "  - Lists and bullet points\n",
    "  - Punctuation and capitalization\n",
    "  - Quotes and emphasis\n",
    "- Each chunk must be **self-contained and semantically meaningful** on its own.\n",
    "- Do not split sentences, arguments, examples, or lists across chunks unless the topic clearly changes.\n",
    "\n",
    "Return your output **exactly** in the format specified by the provided schema.\n",
    "Do not include any explanations or text outside the JSON object.\n",
    "\n",
    "EXTRACTED TEXT:\n",
    "\"\"\"\n",
    "result = chunk_text(system_prompt, user_prompt, extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd8e014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7845"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"data/text/money_stuff_chunked.json\", \"w\").write(result.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
