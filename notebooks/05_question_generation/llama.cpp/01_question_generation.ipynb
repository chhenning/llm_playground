{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcc5b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "from src.data_models import TextChunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b9d296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLAMA_SERVER_URL = \"http://localhost:32000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92980b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "## Money Stuff — Question Generation from Text Chunks\n",
    "\n",
    "### Role\n",
    "You are an expert at writing high-quality, chunk-grounded questions for a newsletter knowledge base.\n",
    "\n",
    "You are given a JSON object containing a list of text chunks. For each chunk, you will create one or more questions that accurately reflect the key points, claims, definitions, mechanisms, examples, or implications in that chunk.\n",
    "\n",
    "These questions will be used later for retrieval, study prompts, and search over the Money Stuff newsletter corpus.\n",
    "\n",
    "---\n",
    "\n",
    "### Input format\n",
    "You will receive input shaped like:\n",
    "\n",
    "{\n",
    "  \"chunks\": [\n",
    "    {\"id\": 1, \"chunk\": \"...\"},\n",
    "    {\"id\": 2, \"chunk\": \"...\"}\n",
    "  ]\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "### Output format (strict)\n",
    "Return only JSON (no markdown, no commentary) in this shape:\n",
    "\n",
    "{\n",
    "  \"questions\": [\n",
    "    {\"chunk_id\": 1, \"questions\": [\"...\", \"...\"]},\n",
    "    {\"chunk_id\": 2, \"questions\": [\"...\"]}\n",
    "  ]\n",
    "}\n",
    "\n",
    "Rules:\n",
    "- Each questions array must contain 1–5 questions (prefer 2–4 when the chunk is dense).\n",
    "- Keep questions answerable using only the chunk.\n",
    "- Do not invent facts, numbers, names, or sources not present in the chunk.\n",
    "- Do not summarize the chunk; write questions that target what the chunk actually says.\n",
    "- Preserve the chunk’s meaning and nuance; avoid leading or loaded phrasing.\n",
    "- If a chunk includes a quote or cited article, you may ask questions about what the quote or article claims, but stay grounded in the provided text.\n",
    "\n",
    "---\n",
    "\n",
    "### What makes a good question\n",
    "Prefer questions that:\n",
    "- Extract the core claim (for example: What is the author arguing about X?)\n",
    "- Capture definitions (for example: What does the author mean by “AI rollups”?)\n",
    "- Ask about mechanisms (for example: How does leverage create upside and downside asymmetry?)\n",
    "- Contrast concepts (for example: How does VC’s “magic technology” differ from PE’s?)\n",
    "- Identify motivations (for example: Why might VCs use rollups now?)\n",
    "- Pull out concrete examples mentioned in the chunk\n",
    "\n",
    "Avoid:\n",
    "- Trivia, unless the chunk is explicitly about that detail\n",
    "- Vague prompts such as “What is this about?”\n",
    "- Multi-part questions that are hard to answer cleanly\n",
    "- Questions that require external context or follow-up knowledge\n",
    "\n",
    "---\n",
    "\n",
    "### Style constraints\n",
    "- Write concise, clear questions.\n",
    "- Use the language and terms from the chunk when helpful (for example: “roll-up,” “non-recourse debt,” “AI agents”).\n",
    "- Use question marks.\n",
    "- Do not exceed roughly 25 words per question unless needed for precision.\n",
    "\n",
    "---\n",
    "\n",
    "### Examples\n",
    "\n",
    "Example input:\n",
    "{\n",
    "  \"chunks\": [\n",
    "    {\n",
    "      \"id\": 1,\n",
    "      \"chunk\": \"# AI rollup\\\\n\\\\nPeople have been worried... We have talked a few times about “AI rollups,” where a venture capital firm buys a bunch of small companies, combines them, and sprinkles them with artificial intelligence.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Example output:\n",
    "{\n",
    "  \"questions\": [\n",
    "    {\n",
    "      \"chunk_id\": 1,\n",
    "      \"questions\": [\n",
    "        \"What is an “AI rollup” as described in this chunk?\",\n",
    "        \"How does the chunk contrast traditional venture capital with the newer rollup approach?\",\n",
    "        \"What kinds of local businesses does the chunk suggest could be targets of AI rollups?\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "Example input:\n",
    "{\n",
    "  \"chunks\": [\n",
    "    {\n",
    "      \"id\": 2,\n",
    "      \"chunk\": \"One way to think about it is that each of PE and VC has a powerful general-purpose technology...\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Example output:\n",
    "{\n",
    "  \"questions\": [\n",
    "    {\n",
    "      \"chunk_id\": 2,\n",
    "      \"questions\": [\n",
    "        \"What does the chunk describe as private equity’s “magic technology,” and how does it work?\",\n",
    "        \"What does the chunk describe as venture capital’s “magic technology,” and what cost reductions does it imply?\",\n",
    "        \"How does the chunk describe the risk and return profile of using leverage in a rollup strategy?\",\n",
    "        \"According to the chunk, what is the longer-term profit opportunity after replacing back-office roles with AI?\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "Example input:\n",
    "{\n",
    "  \"chunks\": [\n",
    "    {\n",
    "      \"id\": 3,\n",
    "      \"chunk\": \"Here’s a Financial Times story about AI rollups: Top venture capital firms are borrowing a strategy...\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Example output:\n",
    "{\n",
    "  \"questions\": [\n",
    "    {\n",
    "      \"chunk_id\": 3,\n",
    "      \"questions\": [\n",
    "        \"According to the quoted Financial Times passage, what strategy are top VCs borrowing from private equity?\",\n",
    "        \"What types of industries does the quote describe as suited to roll-up strategies, and why?\",\n",
    "        \"What does the quote suggest is motivating VCs to pursue rollups right now?\",\n",
    "        \"How does the quote contrast private equity rollups with VC claims about efficiency improvements?\",\n",
    "        \"What is Savvy using AI to do, and what does that illustrate about the rollup thesis?\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "### Final reminder\n",
    "Produce questions for every chunk in the input, using the output format exactly.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa8bfe4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m chunks = \u001b[43mjson\u001b[49m.load(\u001b[33m\"\u001b[39m\u001b[33mdata/text/money_stuff_chunked.md\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m chunks\n",
      "\u001b[31mNameError\u001b[39m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "chunks = json.load(\"data/text/money_stuff_chunked.md\")\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf84558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt tokens  : 868\n",
      "Extracted text tokens : 1548\n",
      "Total tokens          : 2416\n"
     ]
    }
   ],
   "source": [
    "def count_tokens(prompt: str) -> int:\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            url=f\"{LLAMA_SERVER_URL}/tokenize\",\n",
    "            headers={\"Content-Type\": \"application/json\"},\n",
    "            data=json.dumps(\n",
    "                {\n",
    "                    \"content\": prompt,\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "\n",
    "        response_json = response.json()\n",
    "        tokens = response_json.get(\"tokens\", [])\n",
    "\n",
    "        return len(tokens)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return -1\n",
    "\n",
    "system_prompt_tokens = count_tokens(system_prompt)\n",
    "extracted_text_tokens = count_tokens(extracted_text)\n",
    "total_tokens = system_prompt_tokens + extracted_text_tokens\n",
    "\n",
    "print(f\"System prompt tokens  : {system_prompt_tokens}\")\n",
    "print(f\"Extracted text tokens : {extracted_text_tokens}\")\n",
    "print(f\"Total tokens          : {total_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1739cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(system_prompt, user_prompt, text):\n",
    "    try:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt + \"\\n\\n\" + text,\n",
    "            },\n",
    "        ]\n",
    "\n",
    "        payload = {\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": 0,\n",
    "            \"response_format\": {\n",
    "                \"type\": \"json_object\",\n",
    "                \"schema\": TextChunks.model_json_schema(),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        response = requests.post(\n",
    "            url=f\"{LLAMA_SERVER_URL}/v1/chat/completions\",\n",
    "            data=json.dumps(payload),\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "\n",
    "        content = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return TextChunks.model_validate_json(content)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16482684",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Below is the extracted text from a document.\n",
    "\n",
    "Your task is to read the text carefully and split it into **coherent, topic-focused chunks**.\n",
    "\n",
    "Rules:\n",
    "- Each chunk must focus on **one clear topic or idea**.\n",
    "- Do **not** summarize, paraphrase, rewrite, or modify the text in any way.\n",
    "- Do **not** skip or omit any content. Every character must appear in exactly one chunk.\n",
    "- Preserve the **exact text and formatting** as it appears, including:\n",
    "  - Paragraph breaks\n",
    "  - Lists and bullet points\n",
    "  - Punctuation and capitalization\n",
    "  - Quotes and emphasis\n",
    "- Each chunk must be **self-contained and semantically meaningful** on its own.\n",
    "- Do not split sentences, arguments, examples, or lists across chunks unless the topic clearly changes.\n",
    "\n",
    "Return your output **exactly** in the format specified by the provided schema.\n",
    "Do not include any explanations or text outside the JSON object.\n",
    "\n",
    "EXTRACTED TEXT:\n",
    "\"\"\"\n",
    "result = chunk_text(system_prompt, user_prompt, extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd8e014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7845"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"data/text/money_stuff_chunked.json\", \"w\").write(result.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
